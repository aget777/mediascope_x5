{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb278fd8-5db9-4b3d-a6f9-840045cd1a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запрошены записи: 0 - 314\n",
      "Всего найдено записей: 314\n",
      "\n",
      "Запрошены записи: 0 - 314\n",
      "Всего найдено записей: 314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# добавляем библиотеки для работы с ТВ индексом\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import asyncio\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime, date, timedelta, time\n",
    "import time\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "import turbodbc\n",
    "from turbodbc import connect\n",
    "\n",
    "from IPython.display import JSON\n",
    "from mediascope_api.core import net as mscore\n",
    "from mediascope_api.mediavortex import tasks as cwt\n",
    "from mediascope_api.mediavortex import catalogs as cwc\n",
    "\n",
    "import config\n",
    "# import config_tv_index\n",
    "import config_reg_tv\n",
    "# from config_search_funcs import get_subbrand_id_str\n",
    "from normalize_funcs import normalize_columns_types, append_custom_columns, get_tv_type_ooh_reg, get_cleaning_dict, get_media_discounts\n",
    "from db_funcs import createDBTable, downloadTableToDB, get_mssql_table, removeRowsFromDB\n",
    "from create_dicts_tv_index import download_tv_index_default_dicts\n",
    "\n",
    "\n",
    "# Cоздаем объекты для работы с TVI API\n",
    "mnet = mscore.MediascopeApiNetwork()\n",
    "mtask = cwt.MediaVortexTask()\n",
    "cats = cwc.MediaVortexCats()\n",
    "\n",
    "# Забриае название БД\n",
    "db_name = config.db_name\n",
    "\n",
    "# subbrand_id_str = get_subbrand_id_str(mon_num='360', media_type='tv')\n",
    "# special_ad_filter = f'{config_tv_index.nat_tv_ad_filter} AND subbrandId IN ({subbrand_id_str})'\n",
    "# nat_tv_ad_dict = config.nat_tv_ad_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b728af4-8e89-400f-845d-35ad8ae2b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Включаем отображение всех колонок\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Задаем ширину столбцов по контенту\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# убираем лишние предупреждения\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "sep_str = '*' * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bc2355a-3434-4274-875e-19cd531fd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reg_tv_tables():\n",
    "    # специально не стал делать цикл, чтобы явно показать, какие именно создаем таблицы\n",
    "    createDBTable(config.db_name, config_reg_tv.reg_tv_simple , config_reg_tv.reg_tv_simple_vars_list, flag='create')\n",
    "    createDBTable(config.db_name, config_reg_tv.reg_tv_buying , config_reg_tv.reg_tv_buying_vars_list, flag='create')\n",
    "    # создаем пустую таблицу-справочник объявлений\n",
    "    createDBTable(config.db_name, config_reg_tv.reg_tv_ad_dict , config_reg_tv.reg_tv_ad_dict_vars_list, flag='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4a259-ae13-4071-96a1-a042b7ab289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "основная функция для получения данных из Медиаскоп Рег ТВ\n",
    "отчеты Simple / Buying\n",
    "если это первая загрузка, то создаем нужные таблицы в БД\n",
    "добавляем флаг Чистки из гугл докса / если объявление НЕ встречалось, ставим флаг 2\n",
    "номализуем данные - приводим к верхнему регистру / округляем до 2-х знаков после запятой\n",
    "\"\"\"\n",
    "\n",
    "def get_reg_tv_reports(ad_filter=False, start_date='', end_date='', flag='regular'):\n",
    "    start_time = datetime.now()\n",
    "    print(f'Скрипт запущен {start_time}')\n",
    "    # Здесь указаны логические условия ad_filter \n",
    "    # Они применяются для получения статистики в отчетах Simple и Buying# условия фильтрации для запроса \n",
    "    if not ad_filter:\n",
    "        ad_filter = config_reg_tv.reg_tv_ad_filter\n",
    "\n",
    "    if flag.lower()=='first':\n",
    "        create_reg_tv_tables()\n",
    "\n",
    "    # получаем данные из гугл диска с чисткой объявлений \n",
    "    # - передаем список Типов медиа, чтобы оставить нужные значения\n",
    "    # custom_cleaning_dict = get_cleaning_dict(media_type_lst)\n",
    "    # список полей из гугл таблицы Чистка, которые нужно добавить в справочник объявлений\n",
    "    custom_cols_list = [col[:col.find(' ')] for col in config.custom_ad_dict_vars_list]\n",
    "    # убираем некоторые поля, т.е. их заберем из отчета Simple\n",
    "    custom_cols_list = list(set(custom_cols_list) - set(['media_type', 'media_type_long', 'include_exclude', 'tv_type_ooh_reg']))\n",
    "    custom_cols_str = ', '.join(custom_cols_list)\n",
    "\n",
    "    print(sep_str)\n",
    "    print('Забираем из БД НЕ ОБНОВЛЕННЫЙ справочник объявлений')\n",
    "   \n",
    "    query = f\"select {custom_cols_str}  from {config_reg_tv.reg_tv_ad_dict}\"\n",
    "    reg_tv_ad_dict_df = get_mssql_table(config.db_name, query=query)\n",
    "    print(sep_str)\n",
    "    \n",
    "    # # Итоговый список полей, который нам нужен в словаре объявлений\n",
    "    reg_tv_ad_dict_cols_list = [col[:col.find(' ')] for col in config_reg_tv.reg_tv_ad_dict_vars_list]\n",
    "    \n",
    "# Если start_date НЕ передается в функцию - мы считаем, что это еженедельное обновление\n",
    "# Данные в БД TV Index идут с отставанием 3 дня от текущей даты\n",
    "# Нам необходимо перезаписать последние 14 дней\n",
    "# Из текуще даты мы вычитаем 3 дня задержки и 14 дней для перезаписи\n",
    "# это будет считаться датой начала загрузки\n",
    "# удалаем в БД все строки ничиная с этой даты\n",
    "    \n",
    "    if not start_date:\n",
    "        start_date = (datetime.now().date()  - timedelta(days=14+3))\n",
    "\n",
    "    # Если дата окончани загрузки НЕ задана, то мы считаем минус 3 дня от текущей даты\n",
    "    if not end_date:\n",
    "        end_date = (datetime.now().date()  - timedelta(days=3))\n",
    "            \n",
    "    start_date = datetime.strptime(str(start_date), '%Y-%m-%d').date()\n",
    "    end_date = datetime.strptime(str(end_date), '%Y-%m-%d').date()\n",
    "\n",
    "    # если это НЕ первая загрузка, то удаляем строки из БД начиная с даты начала текущей загрузки\n",
    "    # для отчетов Buying - расходы приходят с запозданием на неделю, а так же страхуемся от возможных дублей в БД при новой загрузке\n",
    "    # Например если сегодня 30-е число месяца\n",
    "    # БД еще не обновилась, значит у нас даты до 23-го числа месяца\n",
    "    # Причем с 16 по 23 Расходов НЕТ\n",
    "    # мы запускаем обновление, т.е. забираем данные с 24 по 30\n",
    "    # При этом нам нужно обновить Расхходы с 16 по 23\n",
    "    \n",
    "    if flag=='regular':\n",
    "        cond = f\"researchDate >= '{str(start_date)}' and researchDate <= '{str(end_date)}'\"\n",
    "        \n",
    "        print()\n",
    "        print(sep_str)\n",
    "        print(f'Удалем строки из таблицы: reg_tv_simple и reg_tv_buying по условию: {cond}')\n",
    "        print()\n",
    "    \n",
    "        removeRowsFromDB(config.db_name, config_reg_tv.reg_tv_simple, cond)\n",
    "        removeRowsFromDB(config.db_name, config_reg_tv.reg_tv_buying, cond)\n",
    "        print()\n",
    "    # считаем кол-во дней в периоде\n",
    "    # каждый день мы будем забирать по отдельности и записывать его в БД\n",
    "    count_days = (end_date - start_date).days\n",
    "    \n",
    "    print()\n",
    "    print(f'Загружаем отчет за период {start_date} - {end_date}. Общее количество дней: {count_days+1}')\n",
    "    print(sep_str)\n",
    "    print()\n",
    "\n",
    "    # проходимся по общему количеству дней\n",
    "    for i in range(count_days+1):\n",
    "        # формируем отдельную дату для загрузки\n",
    "        cur_date = str(start_date + relativedelta(days=i))\n",
    "        date_filter = [(cur_date, cur_date)]\n",
    "         # Посчитаем задания в цикле\n",
    "        tasks = []\n",
    "        print()\n",
    "        print(f'{\"=\"*10}Загружаем {cur_date}. Отправляем задания на расчет')\n",
    "        print()\n",
    "        \n",
    "        \n",
    "        for num, (reg_id, reg_name) in enumerate(config_reg_tv.regions_dict.items()):\n",
    "            company_filter = f'regionId IN ({reg_id})'\n",
    "            \n",
    "            print(f'{\"-\"*20} Забираем статистику по отчету Buying -- Region_name: {reg_name} --Дата  {cur_date}')\n",
    "            print(f'Порядковый номер региона {num} из {len(config_reg_tv.regions_dict)}')\n",
    "            print()\n",
    "            # Забираем статистику по отчету Buying\n",
    "            df_buying_final = get_reg_tv_buying_report(ad_filter=ad_filter, date_filter=date_filter, company_filter=company_filter)\n",
    "            df_buying_final['prj_name'] = 'Total_buying_aud'\n",
    "            # Добавляем тип медиа и Дисконты к расходым по годам\n",
    "            df_buying_final = append_custom_columns(df_buying_final, report='buying')\n",
    "            # Прописываем условия для создания колонки tv_type_ooh_reg\n",
    "            df_buying_final = get_tv_type_ooh_reg(df_buying_final)\n",
    "\n",
    "            # забираем список полей, которые созданы в БД в таблице фактов Simple\n",
    "            reg_tv_buying_cols_lst = [col[:col.find(' ')] for col in config_reg_tv.reg_tv_buying_vars_list]\n",
    "            # оставляем только нужные поля в датаФрейме для загрузки в БД\n",
    "            df_buying_final = df_buying_final[reg_tv_buying_cols_lst]\n",
    "            # нормализуем отчет по Баинговой аудитории\n",
    "            df_buying_final = normalize_columns_types(df_buying_final, config_reg_tv.reg_tv_buying_int_lst, config_reg_tv.reg_tv_buying_float_lst)\n",
    "\n",
    "\n",
    "            # загружаем данные в БД по отчету Buying\n",
    "            print('Записываем данные в таблицу фактов Buying')\n",
    "            print()\n",
    "            # записываем в БД отчет по Баинговой аудитории\n",
    "            downloadTableToDB(config.db_name, config_reg_tv.reg_tv_buying, df_buying_final)\n",
    "            # удаляем этот датаФрейм\n",
    "            del df_buying_final\n",
    "    \n",
    "            print()\n",
    "            print(sep_str)\n",
    "        \n",
    "            print()\n",
    "            print(f'{\"-\"*20} Забираем статистику по отчету Simple -- Region_name: {reg_name} --Дата:  {cur_date}')\n",
    "            print(f'Порядковый номер региона {num} из {len(config_reg_tv.regions_dict)}')\n",
    "            print()\n",
    "            # Забираем статистику по отчету Simple\n",
    "            df_simple_final = get_reg_tv_simple_report(ad_filter=ad_filter, date_filter=date_filter, company_filter=company_filter)\n",
    "            # добавляем флаг чистки в датаФрейм\n",
    "            df_simple_final = append_custom_columns(df_simple_final, report='simple', nat_tv_ad_dict=reg_tv_ad_dict_df)\n",
    "            # Прописываем условия для создания колонки tv_type_ooh_reg\n",
    "            df_simple_final = get_tv_type_ooh_reg(df_simple_final)\n",
    "            # Нормализуем все поля в датаФрейме\n",
    "            df_simple_final = normalize_columns_types(df_simple_final, config_reg_tv.reg_tv_simple_int_lst, config_reg_tv.reg_tv_simple_float_lst)\n",
    "\n",
    "            # создаем таблицу с уникальными объявлениями и их характеристиками\n",
    "            simple_ad_dict_df = df_simple_final[reg_tv_ad_dict_cols_list].drop_duplicates('media_key_id')\n",
    "           \n",
    "            # забираем из БД из справочника объявлений уникальные ИД\n",
    "            query = f\"select distinct adId  from {config_reg_tv.reg_tv_ad_dict}\"\n",
    "            reg_tv_ad_id_dict = get_mssql_table(config.db_name, query=query)\n",
    "            # создаем список Уникальных ИД Объявлений, которые уже есть в справочнике в БД\n",
    "            reg_tv_ad_id_lst = list(reg_tv_ad_id_dict['adId'])\n",
    "            # оставляем только те объявления, которых нет в справочнике\n",
    "            simple_ad_dict_df = simple_ad_dict_df.query('adId not in @reg_tv_ad_id_lst')\n",
    "\n",
    "\n",
    "            # на всякий случай обрезаем описание объявления до 500 символов, чтобы не было переполнения строки\n",
    "            simple_ad_dict_df['adNotes'] = simple_ad_dict_df['adNotes'].str.slice(0, 500)\n",
    "            # нормализуем типы данных\n",
    "            simple_ad_dict_df = normalize_columns_types(simple_ad_dict_df, config_reg_tv.reg_tv_ad_dict_int_lst)\n",
    "    \n",
    "            print()\n",
    "            print(sep_str)\n",
    "            print('Записываем данные в справочник объявлений REG TV Index')\n",
    "            print()\n",
    "        \n",
    "            downloadTableToDB(config.db_name, config_reg_tv.reg_tv_ad_dict, simple_ad_dict_df)\n",
    "            \n",
    "            print(sep_str)\n",
    "            print()\n",
    "        \n",
    "            # забираем список полей, которые созданы в БД в таблице фактов Simple\n",
    "            reg_tv_simple_cols_lst = [col[:col.find(' ')] for col in config_reg_tv.reg_tv_simple_vars_list]\n",
    "            # оставляем только нужные поля в датаФрейме для загрузки в БД\n",
    "            df_simple_final = df_simple_final[reg_tv_simple_cols_lst]\n",
    "            \n",
    "            # загружаем данные в БД по отчету Simple\n",
    "            print('Записываем данные в таблицу фактов Simple')\n",
    "            print()\n",
    "            downloadTableToDB(config.db_name, config_reg_tv.reg_tv_simple, df_simple_final)\n",
    "            \n",
    "            print(sep_str)\n",
    "            print()\n",
    "\n",
    "    finish_time = datetime.now()\n",
    "    print(sep_str)\n",
    "    print(f'Время окончания работы скрипта {finish_time}')\n",
    "    print(f'Период загрузки {start_date} - {end_date}. Общее время работы скрипта: {finish_time - start_time}')\n",
    "    print(sep_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1a574b-e42d-473d-b2eb-34314ac5466a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc2cb8-8425-44a9-bb11-9568a69c9dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "УКАЗЫВАЕМ на листе config\n",
    "targets - список аудиторий, по которым нужно собрать датаФрейм\n",
    "ad_filter - условия фильтрации объявлений \n",
    "\n",
    "\n",
    "weekday_filter - Задаем дни недели / Задаем тип дня - daytype_filter / Задаем временной интервал - time_filter\n",
    "Задаем ЦА - basedemo_filter / \n",
    "Доп фильтр ЦА, нужен только в случае расчета отношения между ЦА, например, при расчете Affinity Index - targetdemo_filter\n",
    "Задаем место просмотра - location_filter / Задаем каналы - company_filter\n",
    "Указываем фильтр программ: продолжительность от 5 минут (300 секунд) - program_filter / Фильтр блоков - \n",
    "\"\"\"\n",
    "\n",
    "def get_reg_tv_simple_report(ad_filter=None, weekday_filter=None, date_filter=None,time_filter=None, basedemo_filter=None, targetdemo_filter=None, \n",
    "                             daytype_filter=None,location_filter=None, company_filter=None, program_filter=None, break_filter=None, sortings=None,\n",
    "                            add_city_to_basedemo_from_region=True, add_city_to_targetdemo_from_region=True):\n",
    "    # Cоздаем объекты для работы с TVI API\n",
    "    mnet = mscore.MediascopeApiNetwork()\n",
    "    mtask = cwt.MediaVortexTask()\n",
    "    cats = cwc.MediaVortexCats()\n",
    "    tasks = []\n",
    "    # список аудиторий, по которым собираем статистику\n",
    "    targets = config_reg_tv.reg_tv_targets\n",
    "    # список срезов, по которым будет разбивка отчета\n",
    "    slices = config_reg_tv.reg_tv_slices\n",
    "    # список метрик для отчета Simple\n",
    "    statistics = config_reg_tv.reg_tv_simple_statistics\n",
    "    # Опции для расчета - вся рф и тд.\n",
    "    options = config_reg_tv.reg_tv_options\n",
    "\n",
    "    if targets:\n",
    "        # Для каждой ЦА формируем задание и отправляем на расчет\n",
    "        for target, syntax in targets.items():\n",
    "            # Подставляем значения словаря в параметры\n",
    "            project_name = f\"{target}\" \n",
    "            basedemo_filter = f\"{syntax}\"\n",
    "    \n",
    "            # Формируем задание для API TV Index в формате JSON\n",
    "            task_json = mtask.build_simple_task(date_filter=date_filter, weekday_filter=weekday_filter, \n",
    "                                                daytype_filter=daytype_filter, company_filter=company_filter, \n",
    "                                                location_filter=location_filter, basedemo_filter=basedemo_filter, \n",
    "                                                targetdemo_filter=targetdemo_filter,program_filter=program_filter, \n",
    "                                                break_filter=break_filter, ad_filter=ad_filter, \n",
    "                                                slices=slices, statistics=statistics, sortings=sortings, options=options,\n",
    "                                               add_city_to_basedemo_from_region=add_city_to_basedemo_from_region,\n",
    "                                                add_city_to_targetdemo_from_region=add_city_to_targetdemo_from_region)\n",
    "            \n",
    "            # Для каждого этапа цикла формируем словарь с параметрами и отправленным заданием на расчет\n",
    "            tsk = {}\n",
    "            tsk['project_name'] = project_name    \n",
    "            tsk['task'] = mtask.send_simple_task(task_json)\n",
    "            tasks.append(tsk)\n",
    "            time.sleep(2)\n",
    "\n",
    "        print('')\n",
    "        # Ждем выполнения\n",
    "        print('Ждем выполнения')\n",
    "        tsks = mtask.wait_task(tasks)\n",
    "        print('Расчет завершен, получаем результат')\n",
    "        \n",
    "        # Получаем результат\n",
    "        results = []\n",
    "        print('Собираем таблицу')\n",
    "        \n",
    "        for t in tasks:\n",
    "            tsk = t['task'] \n",
    "            df_result = mtask.result2table(mtask.get_result(tsk), project_name = t['project_name'])        \n",
    "            results.append(df_result)\n",
    "            print('.', end = '')\n",
    "    \n",
    "        df = pd.concat(results)\n",
    "        df = df[['prj_name']+slices+statistics]\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce19b8-bc3c-42f1-aad8-1c25a253682f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4029cdef-3c14-442e-b4b8-2433d2c75c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "УКАЗЫВАЕМ на листе config\n",
    "targets - здесь Обнуляем, т.к. для нам нужен Тотал\n",
    "ad_filter - условия фильтрации объявлений \n",
    "\n",
    "\n",
    "weekday_filter - Задаем дни недели / Задаем тип дня - daytype_filter / Задаем временной интервал - time_filter\n",
    "Задаем ЦА - basedemo_filter / \n",
    "Доп фильтр ЦА, нужен только в случае расчета отношения между ЦА, например, при расчете Affinity Index - targetdemo_filter\n",
    "Задаем место просмотра - location_filter / Задаем каналы - company_filter\n",
    "Указываем фильтр программ: продолжительность от 5 минут (300 секунд) - program_filter / Фильтр блоков - \n",
    "\"\"\"\n",
    "\n",
    "def get_reg_tv_buying_report(ad_filter=None, weekday_filter=None, date_filter=None,time_filter=None, basedemo_filter=None, targetdemo_filter=None, \n",
    "                             daytype_filter=None,location_filter=None, company_filter=None, program_filter=None, break_filter=None, sortings=None,\n",
    "                            add_city_to_basedemo_from_region=True, add_city_to_targetdemo_from_region=True):\n",
    "    # Cоздаем объекты для работы с TVI API\n",
    "    mnet = mscore.MediascopeApiNetwork()\n",
    "    mtask = cwt.MediaVortexTask()\n",
    "    cats = cwc.MediaVortexCats()\n",
    "    tasks = []\n",
    "\n",
    "    # список срезов, по которым будет разбивка отчета по Баинговым аудиториям\n",
    "    slices = config_reg_tv.reg_tv_buying_slices\n",
    "    # список метрик для отчета Buying\n",
    "    statistics = config_reg_tv.reg_tv_bying_statistics\n",
    "    # Опции для расчета - вся рф и тд.\n",
    "    options = config_reg_tv.reg_tv_options\n",
    "\n",
    "    # Формируем задание для API TV Index в формате JSON\n",
    "    task_json = mtask.build_simple_task(date_filter=date_filter, weekday_filter=weekday_filter, \n",
    "                                        daytype_filter=daytype_filter, company_filter=company_filter, \n",
    "                                        location_filter=location_filter, basedemo_filter=basedemo_filter, \n",
    "                                        targetdemo_filter=targetdemo_filter,program_filter=program_filter, \n",
    "                                        break_filter=break_filter, ad_filter=ad_filter, \n",
    "                                        slices=slices, statistics=statistics, sortings=sortings, options=options,\n",
    "                                       add_city_to_basedemo_from_region=add_city_to_basedemo_from_region,\n",
    "                                        add_city_to_targetdemo_from_region=add_city_to_targetdemo_from_region)\n",
    "\n",
    "\n",
    "    # Отправляем задание на расчет и ждем выполнения\n",
    "    task_timeband = mtask.wait_task(mtask.send_simple_task(task_json))\n",
    "    # Получаем результат\n",
    "    df = mtask.result2table(mtask.get_result(task_timeband))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bae7a6-1246-42b9-bd86-ca0ef78fd51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_reg_tv.reg_tv_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ad411-3b72-46e2-b64a-e36e400f862e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd2c68-71a5-4235-ad04-102ab27822fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_date = '2024-01-01'\n",
    "# end_date = '2024-01-01'\n",
    "\n",
    "# date_filter = [(start_date, end_date)]\n",
    "# ad_filter = config_reg_tv.reg_tv_ad_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeb3513-761d-4fdf-94e7-2f3ae6fb2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regions_dict = {\n",
    "#     40: 'БАРНАУЛ',\n",
    "#     # 18: 'ВЛАДИВОСТОК',\n",
    "#     # 5: 'ВОЛГОГРАД',\n",
    "#     # 8: 'ВОРОНЕЖ',\n",
    "#     # 12: 'ЕКАТЕРИНБУРГ',\n",
    "#     # 25: 'ИРКУТСК',\n",
    "#     # 19: 'КАЗАНЬ',\n",
    "#     # 45: 'КЕМЕРОВО',\n",
    "#     # 23: 'КРАСНОДАР',\n",
    "#     # 17: 'КРАСНОЯРСК',\n",
    "#     # 1: 'МОСКВА',\n",
    "#     # 4: 'НИЖНИЙ НОВГОРОД',\n",
    "#     # 15: 'НОВОСИБИРСК',\n",
    "#     # 21: 'ОМСК',\n",
    "#     # 14: 'ПЕРМЬ',\n",
    "#     # 9: 'РОСТОВ-НА-ДОНУ',\n",
    "#     # 6: 'САМАРА',\n",
    "#     # 2: 'САНКТ-ПЕТЕРБУРГ',\n",
    "#     # 10: 'САРАТОВ',\n",
    "#     # 39: 'СТАВРОПОЛЬ',\n",
    "#     # 3: 'ТВЕРЬ',\n",
    "#     # 55: 'ТОМСК',\n",
    "#     # 16: 'ТЮМЕНЬ',\n",
    "#     # 20: 'УФА',\n",
    "#     # 26: 'ХАБАРОВСК',\n",
    "#     # 13: 'ЧЕЛЯБИНСК',\n",
    "#     # 7: 'ЯРОСЛАВЛЬ'\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f491f-6af2-4973-af2f-058f173059a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_buying_final = pd.DataFrame()\n",
    "# for reg_id, reg_name in regions_dict.items():\n",
    "#     company_filter = f'regionId IN ({reg_id})'\n",
    "#     reg_df = get_reg_tv_buying_report(ad_filter=ad_filter, date_filter=date_filter, company_filter=company_filter)\n",
    "#     df_buying_final = pd.concat([df_buying_final, reg_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396fdc2-8c2a-4dae-9df3-8a2cc6f92e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa59989-5e3b-4eb7-a240-4290025115b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_buying_final['ConsolidatedCostRUB'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a38e28-66ce-4a32-9696-b714b7d41197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_buying_final.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bd8a6-c41b-442d-8ba8-17ab3b54bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_cols_list = [col[:col.find(' ')] for col in config.custom_ad_dict_vars_list]\n",
    "# # убираем некоторые поля, т.е. их заберем из отчета Simple\n",
    "# custom_cols_list = list(set(custom_cols_list) - set(['media_type', 'media_type_long', 'include_exclude', 'tv_type_ooh_reg']))\n",
    "# custom_cols_str = ', '.join(custom_cols_list)\n",
    "\n",
    "# print(sep_str)\n",
    "# print('Забираем из БД НЕ ОБНОВЛЕННЫЙ справочник объявлений')\n",
    "\n",
    "# query = f\"select {custom_cols_str}  from {config_reg_tv.reg_tv_ad_dict}\"\n",
    "# reg_tv_ad_dict_df = get_mssql_table(config.db_name, query=query)\n",
    "# print(sep_str)\n",
    "\n",
    "# # # Итоговый список полей, который нам нужен в словаре объявлений\n",
    "# reg_tv_ad_dict_cols_list = [col[:col.find(' ')] for col in config_reg_tv.reg_tv_ad_dict_vars_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d00054-4ab7-48dd-ba2d-119d723d5b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_simple_final = append_custom_columns(df_simple_final, report='simple', nat_tv_ad_dict=reg_tv_ad_dict_df)\n",
    "# # Прописываем условия для создания колонки tv_type_ooh_reg\n",
    "# df_simple_final = get_tv_type_ooh_reg(df_simple_final)\n",
    "# # Нормализуем все поля в датаФрейме\n",
    "# df_simple_final = normalize_columns_types(df_simple_final, config_reg_tv.reg_tv_simple_int_lst, config_reg_tv.reg_tv_simple_float_lst)\n",
    "\n",
    "# # создаем таблицу с уникальными объявлениями и их характеристиками\n",
    "# simple_ad_dict_df = df_simple_final[reg_tv_ad_dict_cols_list].drop_duplicates('media_key_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f36f1-469f-4b4c-a256-c4fb698efacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # забираем список полей, которые созданы в БД в таблице фактов Simple\n",
    "# reg_tv_simple_cols_lst = [col[:col.find(' ')] for col in config_reg_tv.reg_tv_simple_vars_list]\n",
    "# # оставляем только нужные поля в датаФрейме для загрузки в БД\n",
    "# df_simple_final = df_simple_final[reg_tv_simple_cols_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38051812-372d-4d08-96f9-79b51e203ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_buying_final = pd.DataFrame()\n",
    "# for reg_id, reg_name in regions_dict.items():\n",
    "#     company_filter = f'regionId IN ({reg_id})'\n",
    "#     reg_df = get_reg_tv_buying_report(ad_filter=ad_filter, date_filter=date_filter, company_filter=company_filter)\n",
    "#     df_buying_final = pd.concat([df_buying_final, reg_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cfa31d-76d1-4dac-a454-f97ddb635d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createDBTable(config.db_name, config_reg_tv.reg_tv_simple , config_reg_tv.reg_tv_simple_vars_list, flag='create')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb051b7d-5bf7-4ef2-80cc-4d8b0febc77f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40acc15a-5bbb-4c3c-9667-f68e72062509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloadTableToDB(config.db_name, config_reg_tv.reg_tv_simple, df_simple_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
