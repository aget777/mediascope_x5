{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "075a80c4-ba00-47f3-9e43-3a42bcf42dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Запрошены записи: 0 - 314\n",
      "Всего найдено записей: 314\n",
      "\n",
      "Запрошены записи: 0 - 314\n",
      "Всего найдено записей: 314\n",
      "\n",
      "Все ок. Подключились!\n",
      "Загрузка завершена успешно\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "import gc\n",
    "import warnings\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import pyodbc\n",
    "import turbodbc\n",
    "from turbodbc import connect\n",
    "\n",
    "from IPython.display import JSON\n",
    "from mediascope_api.core import net as mscore\n",
    "from mediascope_api.mediavortex import tasks as cwt\n",
    "from mediascope_api.mediavortex import catalogs as cwc\n",
    "\n",
    "# Cоздаем объекты для работы с TVI API\n",
    "mnet = mscore.MediascopeApiNetwork()\n",
    "mtask = cwt.MediaVortexTask()\n",
    "cats = cwc.MediaVortexCats()\n",
    "\n",
    "import config\n",
    "import config_tv_index\n",
    "import config_reg_tv\n",
    "from normalize_funcs import normalize_columns_types, get_cleaning_dict\n",
    "from db_funcs import createDBTable, downloadTableToDB, get_mssql_table\n",
    "\n",
    "\n",
    "db_name = config.db_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3056b8b3-276e-4050-8199-fd42bff8c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Включаем отображение всех колонок\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Задаем ширину столбцов по контенту\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# убираем лишние предупреждения\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c6494c-c9dd-4111-a60f-6804ce60f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "функция для получения справочников из ТВ индекс\n",
    "на входе принимает \n",
    "- название справочника из нашей БД mssql\n",
    "- список ИД для загрузки\n",
    "Мы забираем к себе в БД НЕ все, что есть в ТВ индексе. Нам нужны только те ИД и Названия, категорий, которые встречаются в нашей БД\n",
    "поэтому search_list - это список ИД, которые есть в нашей таблице фактов, но отсутствуют в справочнике\n",
    "- при первой загрузке наши справочники пустые, поэтому в search_lst попадут ВСЕ ИД, котрые нам нужны\n",
    "\"\"\"\n",
    "\n",
    "def get_tv_index_dicts(dict_name, search_lst=None):\n",
    "    if search_lst:\n",
    "        search_lst = [str(id) for id in search_lst]\n",
    "        \n",
    "    if 'advertiserList' in dict_name:\n",
    "        df = cats.get_tv_advertiser_list(search_lst)\n",
    "        df[['name', 'ename']]\n",
    "        df = df.rename(columns={'id': 'advertiserListId', 'name': 'advertiserListName', 'ename': 'advertiserListEName'})\n",
    "\n",
    "    if 'brandList' in dict_name:\n",
    "        df = cats.get_tv_brand_list(search_lst)\n",
    "        df = df.rename(columns={'id': 'brandListId', 'name': 'brandListName', 'ename': 'brandListEName'})\n",
    "        \n",
    "    if 'subbrandList' in dict_name:\n",
    "        df = cats.get_tv_subbrand_list(search_lst)\n",
    "        df = df.rename(columns={'id': 'subbrandListId', 'name': 'subbrandListName', 'ename': 'subbrandListEName'})\n",
    "\n",
    "    if 'modelList'in dict_name:\n",
    "        df = cats.get_tv_model_list(search_lst)\n",
    "        df = df.rename(columns={'id': 'modelListId', 'name': 'modelListName', 'ename': 'modelListEName'})\n",
    "        \n",
    "    if 'articleList2' in dict_name:\n",
    "        df = cats.get_tv_article_list2(search_lst)\n",
    "        df = df.rename(columns={'id': 'articleList2Id', 'name': 'articleList2Name', 'ename': 'articleList2EName'})\n",
    "\n",
    "    if 'articleList3' in dict_name:\n",
    "        df = cats.get_tv_article_list3(search_lst)\n",
    "        df = df.rename(columns={'id': 'articleList3Id', 'name': 'articleList3Name', 'ename': 'articleList3EName'})\n",
    "\n",
    "    if 'articleList4' in dict_name:\n",
    "        df = cats.get_tv_article_list4(search_lst)\n",
    "        df = df.rename(columns={'id': 'articleList4Id', 'name': 'articleList4Name', 'ename': 'articleList4EName'})\n",
    "                                \n",
    "    # if 'adId' in dict_name:\n",
    "    #     df = cats.get_tv_ad(search_lst)\n",
    "    #     df = df.rename(columns={'id': 'adId', 'name': 'adName', 'ename': 'adEName'})\n",
    "\n",
    "    if 'adSloganAudioId' in dict_name:\n",
    "        df = cats.get_tv_ad_slogan_audio(search_lst)\n",
    "        df = df.rename(columns={'id': 'adSloganAudioId', 'name': 'adSloganAudioName', 'notes': 'adSloganAudioNotes'})\n",
    "\n",
    "    if 'adSloganVideo' in dict_name:\n",
    "        df = cats.get_tv_ad_slogan_video(search_lst)\n",
    "        df = df.rename(columns={'id': 'adSloganVideoId', 'name': 'adSloganVideoName', 'notes': 'adSloganVideoNotes'})\n",
    "\n",
    "    if 'region' in dict_name:\n",
    "        df = cats.get_tv_region(search_lst)\n",
    "        df = df.rename(columns={'id': 'regionId', 'name': 'regionName', 'ename': 'regionEName'})\n",
    "\n",
    "    if 'tvNet' in dict_name:\n",
    "        df = cats.get_tv_net()\n",
    "        df = df.rename(columns={'id': 'tvNetId', 'name': 'tvNetName', 'ename': 'tvNetEName'})\n",
    "        df['nid_custom'] = 'tv' + '_' + df['tvNetId'].astype(str)\n",
    "\n",
    "    if 'tvCompany' in dict_name:\n",
    "        df = cats.get_tv_company(search_lst)\n",
    "        df = df.rename(columns={'id': 'tvCompanyId', 'name': 'tvCompanyName', 'ename': 'tvCompanyEName'})\n",
    "        df['cid_custom'] = 'tv' + '_' + df['tvCompanyId'].astype(str)\n",
    "        df['nid_custom'] = 'tv' + '_' + df['tvNetId'].astype(str)\n",
    "\n",
    "    if 'adType' in dict_name:\n",
    "        df = cats.get_tv_ad_type(search_lst)\n",
    "        df = df.rename(columns={'id': 'adTypeId', 'name': 'adTypeName', 'ename': 'adTypeEName'})\n",
    "        df['ad_type_custom'] = 'tv' + '_' + df['adTypeId'].astype(str)\n",
    "\n",
    "    if 'adDistributionType' in dict_name:\n",
    "        df = cats.get_tv_breaks_distribution()\n",
    "        df = df.rename(columns={'id': 'adDistributionType'})\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadccb01-a1c6-4f12-99c5-ffb9d48f0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "функция для обновления всех словарей ТВ индекс КРОМЕ nat_tv_ad_dict\n",
    "После записи данных в отчеты Simple и Buying\n",
    "в справочнике nat_tv_ad_dict - содержится cleanig_flag, который еше НЕ обновился\n",
    "таким образом у нас зафиксировано состояние с прошлой загрузки и мы можем понять, какие новые объявления появилсь в БД\n",
    "для этого по каждому отдельному столбцу, который является ключом для верхнеуровневых справочников\n",
    "мы забираем список уникальных ИД, у которых cleanig_flag=2 (т.е. только новые объявления)\n",
    "список этих ИД мы передаем в запрос к ТВ Индексу, чтобы только то, что нам нужно\n",
    "в конце жобавляем новые строки к справочникам\n",
    "\"\"\"\n",
    "\n",
    "def update_tv_index_dicts():\n",
    "    \n",
    "    # сначала проверяем справочник объявлений - есть там новые или нет\n",
    "    query = f\"select top(1) adId from nat_tv_ad_dict where cleaning_flag=2\"\n",
    "    df = get_mssql_table(config.db_name, query=query)\n",
    "    \n",
    "    # если ответ НЕ пустой, то запускаем логику обновления всех верхнеуровневых справочников\n",
    "    if not df.empty:\n",
    "        # у нас сформирован справочник словарей\n",
    "        # Список параметров словарей ТВ Индекс для создания таблиц в БД и нормализации данных\n",
    "        # Название таблицы / Список названий полей  в БД и типы данных / Список целочисденных полей\n",
    "        for key, value in config_tv_index.tv_index_dicts.items():\n",
    "            # передаем в SQL запрос название поля, которое нас интересует\n",
    "            query = f\"select distinct {key} from nat_tv_ad_dict\"\n",
    "            # отправляем запрос в Общий справочник объявлений\n",
    "            ad_dict= get_mssql_table(config.db_name, query=query)\n",
    "            # переводим ИД в список\n",
    "            ad_dict = ad_dict[key].tolist()\n",
    "            # Готовим запрос к отдельному справочнику, по котором хотим сделать обновление\n",
    "            query = f\"select distinct {key} from {value[0]}\"\n",
    "            target_dict= get_mssql_table(config.db_name, query=query)\n",
    "            # переводим ИД в список\n",
    "            target_dict = target_dict[key].tolist()\n",
    "            \n",
    "            # теперь мы хотим узнать в Общем справочнике nat_tv_ad_dict\n",
    "            # есть ли какие-то ИД, которых НЕТ в другом\n",
    "            search_lst = list(set(ad_dict) - set(target_dict))\n",
    "            # если такие ИД есть, то передаем их на загрузку характеристик из ТВ Индекса\n",
    "            if search_lst:\n",
    "                # отправляем запрос в ТВ индекс\n",
    "                df = get_tv_index_dicts(key, search_lst)\n",
    "                # нормализуем данные\n",
    "                df = normalize_columns_types(df, value[2])\n",
    "                # записываем в БД\n",
    "                downloadTableToDB(db_name, value[0], df)\n",
    "    else:\n",
    "        print(f'Новых данных для загрузки нет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e174fd9-c197-426d-aa18-130523ceb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "с помощью этой функции мы создаем и заполняем словари из ТВ Индекс\n",
    "есть набор некоторы таблиц, которые НЕ связаны с ИД объявления\n",
    "соответсвенно их нет в справочнике nat_tv_ad_dict\n",
    "поэтому при первой загрузке данных мы создаем и сразу заполняем такие справочники\n",
    "в дальнейшешем их НЕ нужно обновлять, т.е. они хранятся в неизменном виде\n",
    "список справочников по умолчанию указан в этом словаре tv_index_default_dicts\n",
    "\"\"\"\n",
    "\n",
    "def download_tv_index_default_dicts():\n",
    "    for key, value in config_tv_index.tv_index_default_dicts.items():\n",
    "        # создаем пустые таблицы для словарей по умолчанию\n",
    "        # createDBTable(db_name, value[0] , value[1], flag='create')\n",
    "        # если таблица уже существовала, то обнуляем в ней данные\n",
    "        createDBTable(db_name, value[0], value[1], flag='drop')\n",
    "        # отправляем запрос в ТВ индекс\n",
    "        df = get_tv_index_dicts(key)\n",
    "        # нормализуем данные\n",
    "        df = normalize_columns_types(df, value[2])\n",
    "        # записываем в БД\n",
    "        downloadTableToDB(db_name, value[0], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f797c2e-9492-488f-bf28-34c63cf46c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# функция для обонвления основного справочнка объявлений nat_tv_ad_dict\n",
    "# ее запускаем в самую после заливки данных из ТВ индекс и обновления всех справочников\n",
    "# НО ПЕРЕД заливкой новых объявлений в гугл докс\n",
    "# \"\"\"\n",
    "\n",
    "# def update_nat_tv_ad_dict(media_type='tv'):\n",
    "#     # забираем гугл докс с чисткой\n",
    "#     df_cleaning_dict = get_cleaning_dict(media_type)\n",
    "   \n",
    "#     media_type_short = media_type.upper()\n",
    "#     # df_cleaning_dict['media_key_id'] = media_type + '_' + df_cleaning_dict['adId'].astype('str')\n",
    "#      # нормализуем типы данных\n",
    "#     df_cleaning_dict = normalize_columns_types(df_cleaning_dict, config.custom_ad_dict_int_lst) \n",
    "    \n",
    "#     # создаем список из названий полей, которые нам нужны дальше для метчинга\n",
    "#     custom_cols_list = [col[:col.find(' ')] for col in config.custom_ad_dict_vars_list]\n",
    "#     custom_cols_list = list(set(custom_cols_list) - set(['adId', 'media_type', 'media_type_long']))\n",
    "#     # оставляем только нужные поля\n",
    "#     df_cleaning_dict = df_cleaning_dict[custom_cols_list]\n",
    "    \n",
    "#     # формируем список названий полей, которые нам нужно забрать из БД\n",
    "#     # из справочника nat_tv_ad_dict\n",
    "#     nat_tv_ad_dict_short_cols = [col[:col.find(' ')] for col in config_tv_index.nat_tv_ad_dict_vars_list]\n",
    "#     nat_tv_ad_dict_short_cols = list(set(nat_tv_ad_dict_short_cols) - set(custom_cols_list)) + ['media_key_id']\n",
    "#     # приводим список к строке\n",
    "#     nat_tv_ad_dict_short_cols = ', '.join(nat_tv_ad_dict_short_cols)\n",
    "    \n",
    "#     # отправляем запрос в БД и забираем ВСЕ строки и нужные поля\n",
    "#     query = f\"select {nat_tv_ad_dict_short_cols}  from {config_tv_index.nat_tv_ad_dict}\"\n",
    "#     nat_tv_ad_dict_df = get_mssql_table(db_name, query=query) \n",
    "\n",
    "#     # объединяем справочник из БД с таблицей чистки\n",
    "#     nat_tv_ad_dict_df = nat_tv_ad_dict_df.merge(df_cleaning_dict, how='left', left_on=['media_key_id'], right_on=['media_key_id'])\n",
    "#     # ИД объявлений, которые НЕ нашли сопосталвения, мы считаем новыми и присваимаем им флаг=2\n",
    "#     nat_tv_ad_dict_df['cleaning_flag'] = nat_tv_ad_dict_df['cleaning_flag'].fillna(2)\n",
    "#     # остальные NaN заполняем пустотой\n",
    "#     nat_tv_ad_dict_df = nat_tv_ad_dict_df.fillna('')\n",
    "#     # создаем список полей, которые нужно оставить в этом датаФрейме\n",
    "#     nat_tv_ad_dict_cols = [col[:col.find(' ')] for col in config_tv_index.nat_tv_ad_dict_vars_list]\n",
    "#     nat_tv_ad_dict_df = nat_tv_ad_dict_df[nat_tv_ad_dict_cols]\n",
    "#     # нормализуем типы данных\n",
    "#     nat_tv_ad_dict_df = normalize_columns_types(nat_tv_ad_dict_df, config_tv_index.nat_tv_ad_dict_int_lst)\n",
    "    \n",
    "#     # удаляем все данные из справочника nat_tv_ad_dict в БД \n",
    "#     createDBTable(db_name, config_tv_index.nat_tv_ad_dict, config_tv_index.nat_tv_ad_dict_vars_list, flag='drop')\n",
    "    \n",
    "#     # записываем новые данные в справочник Объявлений\n",
    "#     downloadTableToDB(db_name, config_tv_index.nat_tv_ad_dict, nat_tv_ad_dict_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e96b9840-e097-4e76-b7c7-61d38950b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "функция для обонвления основного справочнка объявлений nat_tv_ad_dict\n",
    "ее запускаем в самую после заливки данных из ТВ индекс и обновления всех справочников\n",
    "НО ПЕРЕД заливкой новых объявлений в гугл докс\n",
    "\"\"\"\n",
    "\n",
    "def update_nat_tv_ad_dict(media_type='tv', tv_report='nat'):\n",
    "    # забираем гугл докс с чисткой\n",
    "    df_cleaning_dict = get_cleaning_dict(media_type)\n",
    "   \n",
    "    media_type_short = media_type.upper()\n",
    "    # df_cleaning_dict['media_key_id'] = media_type + '_' + df_cleaning_dict['adId'].astype('str')\n",
    "     # нормализуем типы данных\n",
    "    df_cleaning_dict = normalize_columns_types(df_cleaning_dict, config.custom_ad_dict_int_lst) \n",
    "    \n",
    "    # создаем список из названий полей, которые нам нужны дальше для метчинга\n",
    "    custom_cols_list = [col[:col.find(' ')] for col in config.custom_ad_dict_vars_list]\n",
    "    custom_cols_list = list(set(custom_cols_list) - set(['adId', 'media_type', 'media_type_long']))\n",
    "    # оставляем только нужные поля\n",
    "    df_cleaning_dict = df_cleaning_dict[custom_cols_list]\n",
    "    \n",
    "    if tv_report=='nat':\n",
    "        # забираем список полей, которые созданы в БД в таблице фактов Simple\n",
    "        table_name = config_tv_index.nat_tv_ad_dict\n",
    "        vars_cols_lst = config_tv_index.nat_tv_ad_dict_vars_list\n",
    "        int_lst = config_tv_index.nat_tv_ad_dict_int_lst\n",
    "\n",
    "    if tv_report=='reg':\n",
    "        # забираем список полей, которые созданы в БД в таблице фактов Simple\n",
    "        table_name = config_reg_tv.reg_tv_ad_dict\n",
    "        vars_cols_lst = config_reg_tv.reg_tv_ad_dict_vars_list\n",
    "        int_lst = config_reg_tv.reg_tv_ad_dict_int_lst\n",
    "\n",
    "    # формируем список названий полей, которые нам нужно забрать из БД\n",
    "    # из справочника nat_tv_ad_dict\n",
    "    df_ad_dict_short_cols = [col[:col.find(' ')] for col in vars_cols_lst]\n",
    "    df_ad_dict_short_cols = list(set(df_ad_dict_short_cols) - set(custom_cols_list)) + ['media_key_id']\n",
    "    # приводим список к строке\n",
    "    df_ad_dict_short_cols = ', '.join(df_ad_dict_short_cols)\n",
    "    \n",
    "    # отправляем запрос в БД и забираем ВСЕ строки и нужные поля\n",
    "    query = f\"select {df_ad_dict_short_cols}  from {table_name}\"\n",
    "    df_ad_dict = get_mssql_table(db_name, query=query) \n",
    "\n",
    "    # объединяем справочник из БД с таблицей чистки\n",
    "    df_ad_dict = df_ad_dict.merge(df_cleaning_dict, how='left', left_on=['media_key_id'], right_on=['media_key_id'])\n",
    "    # ИД объявлений, которые НЕ нашли сопосталвения, мы считаем новыми и присваимаем им флаг=2\n",
    "    df_ad_dict['cleaning_flag'] = df_ad_dict['cleaning_flag'].fillna(2)\n",
    "    # остальные NaN заполняем пустотой\n",
    "    df_ad_dict = df_ad_dict.fillna('')\n",
    "    # создаем список полей, которые нужно оставить в этом датаФрейме\n",
    "    df_ad_dict_cols = [col[:col.find(' ')] for col in vars_cols_lst]\n",
    "    df_ad_dict = df_ad_dict[df_ad_dict_cols]\n",
    "    # нормализуем типы данных\n",
    "    df_ad_dict = normalize_columns_types(df_ad_dict, int_lst)\n",
    "    \n",
    "    # удаляем все данные из справочника nat_tv_ad_dict в БД \n",
    "    createDBTable(db_name, table_name, vars_cols_lst, flag='drop')\n",
    "    \n",
    "    # записываем новые данные в справочник Объявлений\n",
    "    downloadTableToDB(db_name, table_name, df_ad_dict)\n",
    "    # return df_ad_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
